{
  "textModels": [
    {
      "charge": "1x Query",
      "default": true,
      "defaultPro": false,
      "description": "OpenAI's most scalable and fast model.",
      "id": "gpt-3.5-turbo",
      "name": "GPT 3.5",
      "queryCost": 1,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt-3.webp"
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's latest and fast model.",
      "id": "gpt-4o-mini",
      "name": "GPT 4o Mini",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt-4o.webp"
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": true,
      "description": "OpenAI's flagship model with vision support.",
      "id": "gpt-4o",
      "name": "GPT 4o",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt-4o.webp"
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "Claude 3 Haiku",
      "id": "claude-3-haiku",
      "name": "Claude 3 Haiku",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude-3-haiku.webp"
    },
    {
      "charge": "10x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Claude 3 Sonnet",
      "id": "claude-3-sonnet",
      "name": "Claude 3 Sonnet",
      "queryCost": 10,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude-3-sonnet.webp"
    },
    {
      "charge": "50x Queries",
      "default": false,
      "defaultPro": false,
      "description": "The most capable model across all tasks.",
      "id": "claude-3-opus",
      "name": "Claude 3 Opus",
      "queryCost": 50,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude-3-opus.webp"
    },
    {
      "charge": "25x Queries",
      "default": false,
      "defaultPro": false,
      "description": "The most capable model across all tasks.",
      "id": "claude-3.5-sonnet",
      "name": "Claude 3.5 Sonnet",
      "queryCost": 25,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude-3.5-sonnet.webp"
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "Google's fastest model, gives structured and well crafted answers.",
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gemini-flash.webp"
    },
    {
      "charge": "30x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Google's flagship model, gives structured and well crafted answers.",
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "queryCost": 30,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gemini-pro.webp"
    },
    {
      "charge": "25x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Mistral AI's most capable proprietary model",
      "id": "mistral-large-latest",
      "name": "Mistral Large",
      "queryCost": 25,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/mistral-large.webp"
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "Mistral AI's open source model, good at reasoning with less moderation",
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mixtral",
      "queryCost": 1,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/unknown.webp"
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Meta's latest and best model till date.",
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "name": "Llama 3.1 405B",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/unknown.webp"
    },
    {
      "charge": "40x Queries",
      "default": false,
      "defaultPro": false,
      "description": "O1 Mini",
      "id": "o1-mini",
      "name": "O1 Mini",
      "queryCost": 40,
      "paid": true,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/unknown.webp"
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": false,
      "description": "O3 Mini",
      "id": "o3-mini",
      "name": "O3 Mini",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/o1-old.webp"
    },
    {
      "charge": "180x Queries",
      "default": false,
      "defaultPro": false,
      "description": "O1",
      "id": "o1",
      "name": "O1",
      "queryCost": 180,
      "paid": true,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/unknown.webp"
    },
    {
      "charge": "180x Queries",
      "default": false,
      "defaultPro": false,
      "description": "O1 Preview",
      "id": "o1-preview",
      "name": "O1 Preview",
      "queryCost": 180,
      "paid": true,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/unknown.webp"
    }
  ],
  "textLLMs": [
    {
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's original ChatGPT model",
      "id": "gpt-3.5-turbo",
      "name": "GPT 3.5",
      "queryCost": 1,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt_4o_mini.webp",
      "archived": true,
      "new": false,
      "importance": 1
    },
    {
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's simple and fastest text generation model",
      "id": "gpt-4o-mini",
      "name": "GPT 4o Mini",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt_4o_mini_new.webp",
      "archived": false,
      "new": false,
      "importance": 21,
      "filters": [
        "Speed"
      ]
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's flagship text generation model",
      "id": "gpt-4o",
      "name": "GPT 4o",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt_4o.webp",
      "archived": false,
      "importance": 31,
      "filters": [
        "Reasoning",
        "Writing"
      ]
    },
    {
      "charge": "50x Queries",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's flagship text generation model with longer outputs",
      "id": "gpt-4o-64k-output",
      "name": "GPT 4o (Longer Output)",
      "queryCost": 50,
      "paid": true,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gpt_4o_longer_output.webp",
      "archived": false,
      "importance": 20,
      "filters": [
        "Reasoning",
        "Writing",
        "Coding"
      ]
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's fastest and cheapest model, good for simple tasks",
      "id": "claude-3-haiku",
      "name": "Claude 3 Haiku",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude_3_haiku.webp",
      "archived": false,
      "importance": 23,
      "filters": [
        "Speed"
      ]
    },
    {
      "charge": "5x Query",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's fastest and cheapest model, good for general tasks",
      "id": "claude-3.5-haiku",
      "name": "Claude 3.5 Haiku",
      "queryCost": 5,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude_3_5_haiku.webp",
      "archived": false,
      "importance": 25,
      "filters": [
        "Speed"
      ]
    },
    {
      "charge": "10x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's mid-tier model, 3rd generation",
      "id": "claude-3-sonnet",
      "name": "Claude 3 Sonnet",
      "queryCost": 10,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude_3_sonnet.webp",
      "archived": true,
      "importance": 2
    },
    {
      "charge": "50x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's largest model from 3rd generation",
      "id": "claude-3-opus",
      "name": "Claude 3 Opus",
      "queryCost": 50,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude_3_opus.webp",
      "archived": true,
      "importance": 3
    },
    {
      "charge": "25x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's best model, great across all type of tasks",
      "id": "claude-3.5-sonnet",
      "name": "Claude 3.5 Sonnet",
      "queryCost": 25,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude_3_5_sonnet.webp",
      "archived": true,
      "importance": 32,
      "filters": [
        "Reasoning",
        "Writing",
        "Coding"
      ]
    },
    {
      "charge": "25x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's latest and best model, great across everything",
      "id": "claude-3.7-sonnet",
      "name": "Claude 3.7 Sonnet",
      "queryCost": 25,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude-3-opus.webp",
      "archived": false,
      "importance": 41,
      "filters": [
        "Reasoning",
        "Writing",
        "Coding"
      ]
    },
    {
      "charge": "60x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Anthropic's latest thinking model, great across everything",
      "id": "claude-3.7-sonnet-thinking",
      "name": "Claude 3.7 Sonnet (Thinking)",
      "queryCost": 60,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/claude-3-opus.webp",
      "archived": false,
      "importance": 42,
      "filters": [
        "Reasoning",
        "Writing",
        "Coding"
      ]
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "Google's fastest model with good reasoning",
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gemini_1_5_flash.webp",
      "archived": false,
      "importance": 22,
      "filters": [
        "Speed"
      ]
    },
    {
      "charge": "1x Query",
      "default": true,
      "defaultPro": false,
      "description": "Google's fastest model with good reasoning",
      "id": "gemini-2.0-flash",
      "name": "Gemini 2.0 Flash",
      "queryCost": 1,
      "paid": false,
      "largeContext": true,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gemini_2_0_flash.webp",
      "archived": false,
      "importance": 23,
      "filters": [
        "Speed"
      ]
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Google's flagship model, gives structured and well crafted answers",
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gemini_1_5_pro.webp",
      "archived": true,
      "importance": 35,
      "filters": [
        "Reasoning",
        "Writing"
      ]
    },
    {
      "charge": "10x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Google's flagship model, gives structured and well crafted answers",
      "id": "gemini-2.0-pro",
      "name": "Gemini 2.0 Pro",
      "queryCost": 10,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/gemini_2_0_pro.webp",
      "archived": false,
      "importance": 35,
      "filters": [
        "Reasoning",
        "Writing"
      ]
    },
    {
      "charge": "1x Queries",
      "default": false,
      "defaultPro": false,
      "description": "DeepSeek's newest open source model",
      "id": "deepseek-chat",
      "name": "DeepSeek V3 (US-hosted)",
      "queryCost": 1,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/deepseek_v3.webp",
      "archived": false,
      "importance": 33,
      "filters": [
        "Coding",
        "Writing"
      ],
      "new": true
    },
    {
      "charge": "20x Queries",
      "default": false,
      "defaultPro": false,
      "description": "DeepSeek's newest model that can think",
      "id": "deepseek-reasoner",
      "name": "DeepSeek R1 (US-hosted)",
      "queryCost": 20,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/deepseek_r1.webp",
      "archived": false,
      "importance": 39,
      "filters": [
        "Coding",
        "Writing",
        "Reasoning"
      ],
      "new": true
    },
    {
      "charge": "5x Queries",
      "default": false,
      "defaultPro": false,
      "description": "DeepSeek's newest model that can think. Slower output speed.",
      "id": "deepseek-reasoner-slow",
      "name": "DeepSeek R1 Slow (US-hosted)",
      "queryCost": 5,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/deepseek_r1.webp",
      "archived": false,
      "importance": 38,
      "filters": [
        "Coding",
        "Writing",
        "Reasoning"
      ],
      "new": true
    },
    {
      "charge": "25x Queries",
      "default": false,
      "defaultPro": false,
      "description": "MistralAI's most capable proprietary model",
      "id": "mistral-large-latest",
      "name": "Mistral Large",
      "queryCost": 25,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/mistral-large.webp",
      "archived": true,
      "importance": 15
    },
    {
      "charge": "1x Query",
      "default": false,
      "defaultPro": false,
      "description": "MistralAI's open source model mixture of experts model",
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mixtral",
      "queryCost": 1,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/mistral-large.webp",
      "archived": true,
      "importance": 1
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": false,
      "description": "Meta's latest and best model",
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "name": "Llama 3.1 405B",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/llama.webp",
      "archived": false,
      "importance": 30,
      "filters": [
        "Reasoning"
      ]
    },
    {
      "charge": "40x Queries",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's Chain-Of-Thought based mini model",
      "id": "o1-mini",
      "name": "O1 Mini",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/o1_mini.webp",
      "archived": true,
      "importance": 18,
      "filters": [
        "Reasoning"
      ]
    },
    {
      "charge": "15x Queries",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's New Chain-Of-Thought based mini model",
      "id": "o3-mini",
      "name": "O3 Mini",
      "queryCost": 15,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/o3_mini.webp",
      "archived": false,
      "importance": 28,
      "filters": [
        "Reasoning"
      ]
    },
    {
      "charge": "25x Queries",
      "default": false,
      "defaultPro": true,
      "description": "OpenAI's New Chain-Of-Thought based mini model with higher reasoning",
      "id": "o3-mini-high",
      "name": "O3 Mini High",
      "queryCost": 25,
      "paid": false,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/o3_mini_high.webp",
      "archived": false,
      "importance": 40,
      "filters": [
        "Reasoning"
      ]
    },
    {
      "charge": "180x Queries",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's flagship Chain-Of-Thought based model",
      "id": "o1",
      "name": "O1",
      "queryCost": 180,
      "paid": true,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/o1_new.webp",
      "archived": false,
      "importance": 19,
      "filters": [
        "Reasoning",
        "Coding"
      ]
    },
    {
      "charge": "180x Queries",
      "default": false,
      "defaultPro": false,
      "description": "OpenAI's flagship Chain-Of-Thought based model",
      "id": "o1-preview",
      "name": "O1 Preview",
      "queryCost": 180,
      "paid": true,
      "largeContext": false,
      "icon": "https://cdn.jsdelivr.net/gh/foyer-work/cdn-files@latest/models/o1-old.webp",
      "archived": true,
      "importance": 18,
      "filters": [
        "Reasoning",
        "Coding"
      ]
    }
  ]
}
